{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amlannag/anaconda3/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 148ms/step - accuracy: 0.3855 - loss: 1.7092 - val_accuracy: 0.5935 - val_loss: 1.1453\n",
      "Epoch 2/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 148ms/step - accuracy: 0.5796 - loss: 1.1965 - val_accuracy: 0.6423 - val_loss: 1.0407\n",
      "Epoch 3/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 155ms/step - accuracy: 0.6189 - loss: 1.0766 - val_accuracy: 0.6582 - val_loss: 0.9820\n",
      "Epoch 4/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 176ms/step - accuracy: 0.6443 - loss: 1.0097 - val_accuracy: 0.6817 - val_loss: 0.9168\n",
      "Epoch 5/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 229ms/step - accuracy: 0.6644 - loss: 0.9529 - val_accuracy: 0.6776 - val_loss: 0.9182\n",
      "Epoch 6/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 178ms/step - accuracy: 0.6818 - loss: 0.9091 - val_accuracy: 0.7129 - val_loss: 0.8435\n",
      "Epoch 7/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 216ms/step - accuracy: 0.6964 - loss: 0.8728 - val_accuracy: 0.7172 - val_loss: 0.8211\n",
      "Epoch 8/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 125ms/step - accuracy: 0.7050 - loss: 0.8364 - val_accuracy: 0.7177 - val_loss: 0.8263\n",
      "Epoch 9/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 128ms/step - accuracy: 0.7144 - loss: 0.8244 - val_accuracy: 0.7271 - val_loss: 0.8100\n",
      "Epoch 10/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 153ms/step - accuracy: 0.7187 - loss: 0.8006 - val_accuracy: 0.7350 - val_loss: 0.7831\n",
      "Epoch 11/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 153ms/step - accuracy: 0.7254 - loss: 0.7783 - val_accuracy: 0.7342 - val_loss: 0.7894\n",
      "Epoch 12/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 142ms/step - accuracy: 0.7345 - loss: 0.7527 - val_accuracy: 0.7379 - val_loss: 0.7631\n",
      "Epoch 13/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 149ms/step - accuracy: 0.7392 - loss: 0.7447 - val_accuracy: 0.7303 - val_loss: 0.7841\n",
      "Epoch 14/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 131ms/step - accuracy: 0.7471 - loss: 0.7261 - val_accuracy: 0.7520 - val_loss: 0.7250\n",
      "Epoch 15/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 127ms/step - accuracy: 0.7477 - loss: 0.7184 - val_accuracy: 0.7477 - val_loss: 0.7413\n",
      "Epoch 16/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 146ms/step - accuracy: 0.7558 - loss: 0.6927 - val_accuracy: 0.7444 - val_loss: 0.7433\n",
      "Epoch 17/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 86ms/step - accuracy: 0.7600 - loss: 0.6828 - val_accuracy: 0.7465 - val_loss: 0.7364\n",
      "Epoch 18/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 74ms/step - accuracy: 0.7601 - loss: 0.6861 - val_accuracy: 0.7526 - val_loss: 0.7426\n",
      "Epoch 19/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 78ms/step - accuracy: 0.7713 - loss: 0.6549 - val_accuracy: 0.7596 - val_loss: 0.7171\n",
      "Epoch 20/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 80ms/step - accuracy: 0.7722 - loss: 0.6536 - val_accuracy: 0.7582 - val_loss: 0.7071\n",
      "Epoch 21/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 70ms/step - accuracy: 0.7735 - loss: 0.6501 - val_accuracy: 0.7557 - val_loss: 0.7232\n",
      "Epoch 22/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 89ms/step - accuracy: 0.7759 - loss: 0.6339 - val_accuracy: 0.7546 - val_loss: 0.7225\n",
      "Epoch 23/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 90ms/step - accuracy: 0.7785 - loss: 0.6289 - val_accuracy: 0.7504 - val_loss: 0.7379\n",
      "Epoch 24/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 102ms/step - accuracy: 0.7797 - loss: 0.6226 - val_accuracy: 0.7694 - val_loss: 0.6854\n",
      "Epoch 25/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 102ms/step - accuracy: 0.7813 - loss: 0.6159 - val_accuracy: 0.7669 - val_loss: 0.6894\n",
      "Epoch 26/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 101ms/step - accuracy: 0.7880 - loss: 0.6077 - val_accuracy: 0.7706 - val_loss: 0.6841\n",
      "Epoch 27/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 91ms/step - accuracy: 0.7899 - loss: 0.6006 - val_accuracy: 0.7654 - val_loss: 0.7123\n",
      "Epoch 28/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 84ms/step - accuracy: 0.7911 - loss: 0.6003 - val_accuracy: 0.7645 - val_loss: 0.7176\n",
      "Epoch 29/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 82ms/step - accuracy: 0.7921 - loss: 0.5920 - val_accuracy: 0.7658 - val_loss: 0.6977\n",
      "Epoch 30/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 80ms/step - accuracy: 0.7979 - loss: 0.5805 - val_accuracy: 0.7625 - val_loss: 0.7123\n",
      "Epoch 31/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 79ms/step - accuracy: 0.7939 - loss: 0.5827 - val_accuracy: 0.7655 - val_loss: 0.7102\n",
      "Epoch 32/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 83ms/step - accuracy: 0.8004 - loss: 0.5754 - val_accuracy: 0.7641 - val_loss: 0.7146\n",
      "Epoch 33/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 81ms/step - accuracy: 0.7950 - loss: 0.5845 - val_accuracy: 0.7679 - val_loss: 0.7010\n",
      "Epoch 34/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 77ms/step - accuracy: 0.7962 - loss: 0.5722 - val_accuracy: 0.7721 - val_loss: 0.6859\n",
      "Epoch 35/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 75ms/step - accuracy: 0.8019 - loss: 0.5616 - val_accuracy: 0.7666 - val_loss: 0.6991\n",
      "Epoch 36/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 78ms/step - accuracy: 0.8046 - loss: 0.5550 - val_accuracy: 0.7687 - val_loss: 0.6925\n",
      "Epoch 37/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 76ms/step - accuracy: 0.8045 - loss: 0.5608 - val_accuracy: 0.7797 - val_loss: 0.6789\n",
      "Epoch 38/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 70ms/step - accuracy: 0.8056 - loss: 0.5462 - val_accuracy: 0.7774 - val_loss: 0.6768\n",
      "Epoch 39/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 72ms/step - accuracy: 0.8099 - loss: 0.5447 - val_accuracy: 0.7805 - val_loss: 0.6835\n",
      "Epoch 40/40\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 76ms/step - accuracy: 0.8062 - loss: 0.5486 - val_accuracy: 0.7728 - val_loss: 0.7032\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
      "[3 8 8 ... 5 4 7]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81      1000\n",
      "           1       0.80      0.91      0.85      1000\n",
      "           2       0.69      0.71      0.70      1000\n",
      "           3       0.65      0.53      0.58      1000\n",
      "           4       0.76      0.74      0.75      1000\n",
      "           5       0.74      0.64      0.69      1000\n",
      "           6       0.70      0.89      0.78      1000\n",
      "           7       0.83      0.84      0.84      1000\n",
      "           8       0.91      0.81      0.86      1000\n",
      "           9       0.85      0.84      0.85      1000\n",
      "\n",
      "    accuracy                           0.77     10000\n",
      "   macro avg       0.77      0.77      0.77     10000\n",
      "weighted avg       0.77      0.77      0.77     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import data and split testing and training\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Outline the height, width, and number of channels\n",
    "samples, height, width, channels = X_train.shape\n",
    "\n",
    "categories = len(np.unique(y_train))\n",
    "y_train_cat = to_categorical(y_train, categories)\n",
    "y_test_cat = to_categorical(y_test, categories)\n",
    "\n",
    "# Normalize data\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Calculate mean and std for each channel\n",
    "mean = np.mean(X_train, axis=(0, 1, 2), keepdims=True)\n",
    "std = np.std(X_train, axis=(0, 1, 2), keepdims=True)\n",
    "\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    height_shift_range=0.1,\n",
    "    width_shift_range=0.1,\n",
    "    fill_mode='reflect'\n",
    ")\n",
    "\n",
    "# Fit the data generator to the training data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "inputs = Input(shape=(height, width, channels))\n",
    "net1 = Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\")(inputs)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(net1)\n",
    "net2 = Conv2D(filters=32, kernel_size=(3, 3), padding=\"same\", activation=\"relu\")(pool1)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(net2)\n",
    "flat = Flatten()(pool2)\n",
    "net3 = Dense(128, activation=\"relu\")(flat)\n",
    "output = Dense(categories, activation=\"softmax\")(net3)\n",
    "\n",
    "model = Model(inputs, output)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Using ImageDataGenerator with flow to generate augmented batches\n",
    "model.fit(datagen.flow(X_train, y_train_cat, batch_size=128),\n",
    "          epochs=40,\n",
    "          validation_data=(X_test, y_test_cat))\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "print(predictions)\n",
    "\n",
    "#print performance to compare with previous RF versions\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
